{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/t.tovi/packages/dss/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dss.env import DollyEnv\n",
    "from dss.transformation import SentenceTransformerFeature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from torch.utils.data import Dataset\n",
    "from os import path\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this new env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed features...\n"
     ]
    }
   ],
   "source": [
    "env = DollyEnv(use_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed features...\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: DollyEnv(use_raw=False, cov_metric=\"dissimilarity\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/t.tovi/packages/dss/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the policy using PPO\n",
    "retrain = False\n",
    "agent = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "if path.exists(\"playground/ppo_dolly_instruct.zip\") and not retrain:\n",
    "    agent = PPO.load(\"playground/ppo_dolly_instruct.zip\", env=env)\n",
    "else:\n",
    "    agent.learn(total_timesteps=int(1e5))\n",
    "    agent.save(\"playground/ppo_dolly_instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us measure diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15011 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 2233/15011 [00:10<00:55, 231.38it/s]"
     ]
    }
   ],
   "source": [
    "train_dataset = env.envs[0].dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "X = []\n",
    "data_values = []\n",
    "for datum in tqdm.tqdm(train_loader):\n",
    "    state = datum['feature']\n",
    "    _, log_likelihoods, _ = agent.policy.evaluate_actions(state.to(0), torch.tensor([0, 1]).to(0))\n",
    "    \n",
    "    datum_value = log_likelihoods[1].cpu().item()\n",
    "\n",
    "    X.append(datum)\n",
    "    data_values.append(datum_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = [x for x, _ in sorted(zip(X, data_values), key=lambda x: x[-1], reverse=True)]\n",
    "X_ = np.array(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1, Covariance: 0.9719694256782532\n",
      "Size: 6, Covariance: 0.9806336164474487\n",
      "Size: 11, Covariance: 0.9769279956817627\n",
      "Size: 16, Covariance: 0.9724605679512024\n",
      "Size: 21, Covariance: 0.9680395126342773\n",
      "Size: 26, Covariance: 0.9637230634689331\n",
      "Size: 31, Covariance: 0.9596344232559204\n",
      "Size: 36, Covariance: 0.9561107754707336\n",
      "Size: 41, Covariance: 0.952923595905304\n",
      "Size: 46, Covariance: 0.9498034715652466\n",
      "Size: 51, Covariance: 0.9470767974853516\n",
      "Size: 56, Covariance: 0.944887638092041\n",
      "Size: 61, Covariance: 0.9426226019859314\n",
      "Size: 66, Covariance: 0.9405233263969421\n",
      "Size: 71, Covariance: 0.9385395646095276\n",
      "Size: 76, Covariance: 0.9367333650588989\n",
      "Size: 81, Covariance: 0.9348382949829102\n",
      "Size: 86, Covariance: 0.9330253601074219\n",
      "Size: 91, Covariance: 0.931355357170105\n",
      "Size: 96, Covariance: 0.9298263192176819\n"
     ]
    }
   ],
   "source": [
    "for size in range(1, 101, 5):\n",
    "\n",
    "    indices = np.arange(int(size/100*len(X_)))\n",
    "    samples = X_[indices]\n",
    "    samples = np.array([s['feature'].numpy() for s in samples])\n",
    "    samples = samples.reshape(samples.shape[0], -1)\n",
    "    samples = torch.from_numpy(samples)\n",
    "    #d = torch.diag(torch.cov(samples.T)).sum()\n",
    "    d = np.mean(cosine_distances(samples.cpu().numpy()))\n",
    "    print(f\"Size: {size}, Covariance: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1, Covariance: 0.8834326267242432\n",
      "Size: 6, Covariance: 0.8833936452865601\n",
      "Size: 11, Covariance: 0.8862953782081604\n",
      "Size: 16, Covariance: 0.8891157507896423\n",
      "Size: 21, Covariance: 0.8910645246505737\n",
      "Size: 26, Covariance: 0.8927051424980164\n",
      "Size: 31, Covariance: 0.8949320912361145\n",
      "Size: 36, Covariance: 0.8967922329902649\n",
      "Size: 41, Covariance: 0.8986470103263855\n",
      "Size: 46, Covariance: 0.9008399844169617\n",
      "Size: 51, Covariance: 0.9025696516036987\n",
      "Size: 56, Covariance: 0.9038946628570557\n",
      "Size: 61, Covariance: 0.9059028625488281\n",
      "Size: 66, Covariance: 0.9076675772666931\n",
      "Size: 71, Covariance: 0.9097478985786438\n",
      "Size: 76, Covariance: 0.9118421673774719\n",
      "Size: 81, Covariance: 0.9143750667572021\n",
      "Size: 86, Covariance: 0.9172683954238892\n",
      "Size: 91, Covariance: 0.9207983613014221\n",
      "Size: 96, Covariance: 0.9248338937759399\n"
     ]
    }
   ],
   "source": [
    "for size in range(1, 101, 5):\n",
    "\n",
    "    indices = -np.arange(int(size/100*len(X_)))\n",
    "    samples = X_[indices]\n",
    "    samples = np.array([s['feature'].numpy() for s in samples])\n",
    "    samples = samples.reshape(samples.shape[0], -1)\n",
    "    samples = torch.from_numpy(samples)\n",
    "    #d = torch.diag(torch.cov(samples.T)).sum()\n",
    "    d = np.mean(cosine_distances(samples.cpu().numpy()))\n",
    "    print(f\"Size: {size}, Covariance: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1, Covariance: 0.9211809635162354\n",
      "Size: 6, Covariance: 0.9246454238891602\n",
      "Size: 11, Covariance: 0.928205668926239\n",
      "Size: 16, Covariance: 0.9297683238983154\n",
      "Size: 21, Covariance: 0.927932620048523\n",
      "Size: 26, Covariance: 0.927312970161438\n",
      "Size: 31, Covariance: 0.9288177490234375\n",
      "Size: 36, Covariance: 0.9287832379341125\n",
      "Size: 41, Covariance: 0.9281821846961975\n",
      "Size: 46, Covariance: 0.9292672276496887\n",
      "Size: 51, Covariance: 0.9290285706520081\n",
      "Size: 56, Covariance: 0.9288315773010254\n",
      "Size: 61, Covariance: 0.9286008477210999\n",
      "Size: 66, Covariance: 0.9289616942405701\n",
      "Size: 71, Covariance: 0.9288148880004883\n",
      "Size: 76, Covariance: 0.9281294941902161\n",
      "Size: 81, Covariance: 0.9289678931236267\n",
      "Size: 86, Covariance: 0.9287742376327515\n",
      "Size: 91, Covariance: 0.9290452003479004\n",
      "Size: 96, Covariance: 0.9289625883102417\n"
     ]
    }
   ],
   "source": [
    "for size in range(1, 101, 5):\n",
    "\n",
    "    indices = np.random.choice(len(X_), int(size/100*len(X_)), replace=False)\n",
    "    samples = X_[indices]\n",
    "    samples = np.array([s['feature'].numpy() for s in samples])\n",
    "    samples = samples.reshape(samples.shape[0], -1)\n",
    "    samples = torch.from_numpy(samples)\n",
    "    #d = torch.diag(torch.cov(samples.T)).sum()\n",
    "    d = np.mean(cosine_distances(samples.cpu().numpy()))\n",
    "    print(f\"Size: {size}, Covariance: {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare it with DPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "F_ = [x['feature'].flatten() for x in X_]\n",
    "F_ = torch.stack(F_)\n",
    "\n",
    "kernel_matrix = rbf_kernel(F_.cpu().numpy(), gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dss.utils import dpp\n",
    "\n",
    "max_size = int(0.5 * len(X_))\n",
    "selected_indices_ = dpp(kernel_matrix, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9862835\n",
      "0.98327124\n",
      "0.9802927\n",
      "0.97673607\n",
      "0.9731184\n",
      "0.9693479\n",
      "0.965731\n",
      "0.9623316\n",
      "0.95870185\n",
      "0.95539033\n",
      "0.952868\n"
     ]
    }
   ],
   "source": [
    "size = 600\n",
    "for percentage in range(1, 52, 5):\n",
    "    size_ = len(X_) * percentage // 100\n",
    "    samples = F_[selected_indices_[:size_]]\n",
    "    d = np.mean(cosine_distances(samples.cpu().numpy()))\n",
    "    print(d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = [{k:v for k,v in d.items() if k!=\"feature\"} for d in X_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/llama-2-7b-hf\")\n",
    "\n",
    "to_save = [entry for entry in to_save if tokenizer(entry['context'])[\"input_ids\"][0].__len__() <= 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open (\"playground/dolly_6k_dss.json\", \"w\") as f:\n",
    "    json.dump(to_save[:6000], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "random_save = np.array(to_save)\n",
    "random_save = random_save[np.random.choice(len(random_save), 6000, replace=False)]\n",
    "with open (\"playground/dolly_6k_random.json\", \"w\") as f:\n",
    "    json.dump(random_save.tolist(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
